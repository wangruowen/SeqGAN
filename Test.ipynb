{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import linecache\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SeqGAN.train import *\n",
    "from SeqGAN.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\n",
    "    'batch_size': 128,\n",
    "    'max_length': 15,\n",
    "    'max_words': 10000,\n",
    "    'gen_embed': 100,\n",
    "    'dis_embed': 100,\n",
    "    'gen_hidden': 128,\n",
    "    'dis_hidden': 128,\n",
    "    'dis_dropout': 0.2,\n",
    "    'gen_lr': 1e-3,\n",
    "    'dis_lr': 1e-3,\n",
    "    'mcts_sample': 10,\n",
    "    'gen_samples': 1000,\n",
    "    'gen_sample_length': 50,  # Generated sample can be longer than max_length\n",
    "\n",
    "    'rnn_layers': 3,\n",
    "    'rnn_bidirectional': False,\n",
    "\n",
    "    'gen_pretrain_epoch': 10,\n",
    "    'dis_pretrain_epoch': 1,\n",
    "    \n",
    "    'g_pretrain_epochs': 20,\n",
    "    'd_pretrain_epochs': 1,\n",
    "    'train_steps': 50,\n",
    "    'g_steps': 1,\n",
    "    'd_steps': 1,\n",
    "    'd_epochs': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word2id:  10004\n",
      "Total id2word:  10004\n",
      "Num of positive training:  398450\n",
      "Num of positive validation:  0\n",
      "WARNING:tensorflow:From /home/wangruowen/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/wangruowen/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/wangruowen/.pyenv/versions/3.6.3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config, \"./data/just_tweet_without_I_will_be_interviewed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator pre-training\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "Embedding (Embedding)        (None, 15, 100)           1000400   \n",
      "_________________________________________________________________\n",
      "rnn_1 (CuDNNLSTM)            (None, 15, 128)           117760    \n",
      "_________________________________________________________________\n",
      "rnn_2 (CuDNNLSTM)            (None, 15, 128)           132096    \n",
      "_________________________________________________________________\n",
      "rnn_3 (CuDNNLSTM)            (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "DenseSoftmax (Dense)         (None, 10004)             1290516   \n",
      "=================================================================\n",
      "Total params: 2,672,868\n",
      "Trainable params: 2,672,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "3112/3112 [==============================] - 29s 9ms/step - loss: 6.1069\n",
      "Epoch 2/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 5.3580\n",
      "Epoch 3/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 5.0228\n",
      "Epoch 4/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.8000\n",
      "Epoch 5/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.6263\n",
      "Epoch 6/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.4818\n",
      "Epoch 7/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.3617\n",
      "Epoch 8/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.2589\n",
      "Epoch 9/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.1696\n",
      "Epoch 10/10\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.0905\n"
     ]
    }
   ],
   "source": [
    "trainer.pre_train_generator(g_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Generating 1000 sentences\n",
      "Num of all training:  433593\n",
      "Num of all validation:  0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "Embedding (Embedding)        (None, 15, 100)           1000400   \n",
      "_________________________________________________________________\n",
      "rnn_1 (CuDNNLSTM)            (None, 15, 128)           117760    \n",
      "_________________________________________________________________\n",
      "rnn_2 (CuDNNLSTM)            (None, 15, 128)           132096    \n",
      "_________________________________________________________________\n",
      "rnn_3 (CuDNNLSTM)            (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "FC (Dense)                   (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,382,481\n",
      "Trainable params: 1,382,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Discriminator pre-training\n",
      "Epoch 1/1\n",
      "3387/3387 [==============================] - 20s 6ms/step - loss: 0.0750\n"
     ]
    }
   ],
   "source": [
    "trainer.pre_train_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "****GAN step:  0\n",
      "Train Generator at round  0\n",
      "Reward: 0.752, Episode end\n",
      "Loss:  12.523416\n",
      "<BOS> the democrats of the president department of the american people out by the people of\n",
      "<BOS> thank you for all of my support ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> the failing @nytimes is totally more than the democrats and not a total witch hunt\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  1\n",
      "Reward: 0.643, Episode end\n",
      "Loss:  9.245862\n",
      "<BOS> i will be on the world of the trump post ' s \" <EOS> <PAD>\n",
      "<BOS> i am the new new hunt last night . i am a great job for\n",
      "<BOS> the super bowl in @trumpdoral : \" trump <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  2\n",
      "Reward: 0.620, Episode end\n",
      "Loss:  7.857127\n",
      "<BOS> act to the great state of the great states . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> . i love you to the great states ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> . _ joe : \" trump : \" trump : \" trump \" <EOS> <PAD>\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  3\n",
      "Reward: 0.584, Episode end\n",
      "Loss:  6.9257903\n",
      "<BOS> a great honor to the great states of the great states of the people of\n",
      "<BOS> wow the u . s . the great states of the great states of the\n",
      "<BOS> democrats are a great job of the border of the great states of the border\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  4\n",
      "Reward: 0.582, Episode end\n",
      "Loss:  6.3519583\n",
      "<BOS> the only thing that the \" \" trump \" \" trump : \" trump :\n",
      "<BOS> . _ _ int \" _ vegas by the great states of the great states\n",
      "<BOS> . _ joe by the big state of the great states of the great states\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  449813\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3514/3514 [==============================] - 21s 6ms/step - loss: 0.0284\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  1\n",
      "Train Generator at round  0\n",
      "Reward: 0.051, Episode end\n",
      "Loss:  0.5065098\n",
      "<BOS> . _ _ _ poll by the great states of the great states of the\n",
      "<BOS> . _ \" by the great states of the great states of the great states\n",
      "<BOS> it . i ' ll the great states of the great states of the great\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  1\n",
      "Reward: 0.059, Episode end\n",
      "Loss:  0.58626825\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "<BOS> . _ york by the great states of the great states of the great states\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  2\n",
      "Reward: 0.043, Episode end\n",
      "Loss:  0.42271122\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "<BOS> . _ \" _ by the great states of the great states of the great\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  3\n",
      "Reward: 0.049, Episode end\n",
      "Loss:  0.47017315\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "<BOS> . _ vegas by the great states of the great states of the great states\n",
      "<BOS> . _ vegas by the great states of the great states of the great states\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  4\n",
      "Reward: 0.053, Episode end\n",
      "Loss:  0.5035163\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "<BOS> . _ new . _ vegas by the great states of the great states of\n",
      "<BOS> . _ _ _ _ by by the great states of the great states of\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  450182\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3517/3517 [==============================] - 20s 6ms/step - loss: 0.0238\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  2\n",
      "Train Generator at round  0\n",
      "Reward: 0.131, Episode end\n",
      "Loss:  1.3902365\n",
      "<BOS> . _ _ _ poll by the great states of the great states of the\n",
      "<BOS> hillary . \" trump . \" trump . \" trump by the great states of\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  1\n",
      "Reward: 0.114, Episode end\n",
      "Loss:  1.1996408\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "<BOS> . _ by the great states of the great states of the great states of\n",
      "<BOS> . _ vegas by the great states of the great states of the great states\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  2\n",
      "Reward: 0.106, Episode end\n",
      "Loss:  1.068517\n",
      "<BOS> . _ vegas by the great states of the great states of the great states\n",
      "<BOS> . _ vegas by _ vegas by the great states of the great states of\n",
      "<BOS> . _ joe by the great states of the great states of the great states\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  3\n",
      "Reward: 0.119, Episode end\n",
      "Loss:  1.186626\n",
      "<BOS> . _ by by the great states of the great states of the great states\n",
      "<BOS> . _ by by the great states of the great states of the great states\n",
      "<BOS> . _ by by the great states of the great states of the great states\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  4\n",
      "Reward: 0.147, Episode end\n",
      "Loss:  1.5388103\n",
      "<BOS> . _ by by the great states of the great states of the great states\n",
      "<BOS> . _ by by the great states of the great states of the great states\n",
      "<BOS> \" by the united states of the great states of the great states of the\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  449862\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3514/3514 [==============================] - 20s 6ms/step - loss: 0.0228\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  3\n",
      "Train Generator at round  0\n",
      "Reward: 0.096, Episode end\n",
      "Loss:  1.0055183\n",
      "<BOS> . _ vegas by by by the new hunt by the great states of the\n",
      "<BOS> . _ vegas by by by the great states of the great states of the\n",
      "<BOS> . _ by by by by the great states of the great states of the\n",
      "--------------------------------------------------------------------------------\n",
      "Train Generator at round  1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bb7438d06d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/lv_disk1/git/cs230_Final_Project/SeqGAN_keras/SeqGAN/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, steps, g_steps, d_steps, d_epochs, g_weights_path, d_weights_path, verbose, head)\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, 1/T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_episode_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                     \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lv_disk1/git/cs230_Final_Project/SeqGAN_keras/SeqGAN/rl.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         '''\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;31m# print(\"reward: \", reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lv_disk1/git/cs230_Final_Project/SeqGAN_keras/SeqGAN/rl.py\u001b[0m in \u001b[0;36mQ\u001b[0;34m(self, action, n_sample)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# From t+1 to T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# print(\"Rollout: \", tau)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_beta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_beta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# print(\"Y.shape: \", Y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lv_disk1/git/cs230_Final_Project/SeqGAN_keras/SeqGAN/rl.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state, epsilon, deterministic)\u001b[0m\n\u001b[1;32m     40\u001b[0m         '''\n\u001b[1;32m     41\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_act_on_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_act_on_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPAD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lv_disk1/git/cs230_Final_Project/SeqGAN_keras/SeqGAN/rl.py\u001b[0m in \u001b[0;36m_act_on_word\u001b[0;34m(self, word, epsilon, deterministic, PAD, EOS)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, V)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_one_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lv_disk1/git/cs230_Final_Project/SeqGAN_keras/SeqGAN/utils.py\u001b[0m in \u001b[0;36msample_one_word\u001b[0;34m(preds, temperature)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# probas = np.random.multinomial(1, preds[i], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;31m# index = np.argmax(probas)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(steps=20, g_steps=5, d_steps=1, d_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "****GAN step:  0\n",
      "Train Generator at round  0\n",
      "Reward: 0.479, Episode end\n",
      "Loss:  8.240981\n",
      "<BOS> i am saying that the american people are doing a great state of the world\n",
      "<BOS> . will be a great job in the world - we have a great job\n",
      "<BOS> great day from my friend and many more and killing the u . s .\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  431428\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3370/3370 [==============================] - 19s 6ms/step - loss: 0.0489\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  1\n",
      "Train Generator at round  0\n",
      "Reward: 0.347, Episode end\n",
      "Loss:  5.474699\n",
      "<BOS> \" <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> very unfair to the u . s . enjoy to the u . s .\n",
      "<BOS> we are a great job in the world of the u . s . enjoy\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  426347\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3330/3330 [==============================] - 18s 6ms/step - loss: 0.0384\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  2\n",
      "Train Generator at round  0\n",
      "Reward: 0.226, Episode end\n",
      "Loss:  3.1806188\n",
      "<BOS> the trump post office in the trump @clemsonfb golf by ferry to the trump @abeshinzo\n",
      "<BOS> . i ' ve no longer that it is a great job . <EOS> <PAD>\n",
      "<BOS> \" donald trump unveils <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  428292\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3346/3346 [==============================] - 19s 6ms/step - loss: 0.0330\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  3\n",
      "Train Generator at round  0\n",
      "Reward: 0.236, Episode end\n",
      "Loss:  3.1634636\n",
      "<BOS> crooked hillary clinton ' s \" <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> . i ' ll be a great new carolina and the new office to the\n",
      "<BOS> the u . s . trump is a new radical trump @clemsonfb hotel at the\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  433742\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3388/3388 [==============================] - 19s 6ms/step - loss: 0.0284\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  4\n",
      "Train Generator at round  0\n",
      "Reward: 0.188, Episode end\n",
      "Loss:  2.339233\n",
      "<BOS> \" a hillary ' s donald trump ' s called a great \" s .\n",
      "<BOS> the the trump national doral \" the u . s . trump is a the\n",
      "<BOS> the florida of the u . s . s . enjoy to the trump national\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  436906\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3413/3413 [==============================] - 20s 6ms/step - loss: 0.0257\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  5\n",
      "Train Generator at round  0\n",
      "Reward: 0.175, Episode end\n",
      "Loss:  2.1163185\n",
      "<BOS> the the new office . congress are a great great great great great great great\n",
      "<BOS> . i will be a great great great great great great great great great great\n",
      "<BOS> . i will be a great great great again ! <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  442191\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3454/3454 [==============================] - 20s 6ms/step - loss: 0.0240\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  6\n",
      "Train Generator at round  0\n",
      "Reward: 0.161, Episode end\n",
      "Loss:  2.0829518\n",
      "<BOS> . i ' ve ' s ' s ' s ' s ' s '\n",
      "<BOS> the new new new new new office . i will be the great office .\n",
      "<BOS> for the u . s . s . s . s . s . enjoy\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  445822\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "3482/3482 [==============================] - 21s 6ms/step - loss: 0.0220\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "****GAN step:  7\n",
      "Train Generator at round  0\n",
      "Reward: 0.131, Episode end\n",
      "Loss:  1.6124243\n",
      "<BOS> ! # trump2016 # trump2016 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BOS> . the new new office . i will be a great great great great great\n",
      "<BOS> . i ' ve ' ll be a great great great great great great great\n",
      "--------------------------------------------------------------------------------\n",
      "Train Discriminator at round  0\n",
      "Start Generating 1000 sentences\n",
      "Num of all training:  448301\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "2174/3502 [=================>............] - ETA: 7s - loss: 0.0210"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fd2601120d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/lv_disk1/git/cs230_Final_Project/SeqGAN_keras/SeqGAN/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, steps, g_steps, d_steps, d_epochs, g_weights_path, d_weights_path, verbose, head)\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_train_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;31m# Update env.g_beta to agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(steps=20, g_steps=1, d_steps=1, d_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
