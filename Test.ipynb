{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import linecache\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SeqGAN.train import *\n",
    "from SeqGAN.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\n",
    "    'batch_size': 128,\n",
    "    'max_length': 15,\n",
    "    'max_words': 10000,\n",
    "    'gen_embed': 100,\n",
    "    'dis_embed': 100,\n",
    "    'gen_hidden': 128,\n",
    "    'dis_hidden': 128,\n",
    "    'dis_dropout': 0.2,\n",
    "    'gen_lr': 1e-3,\n",
    "    'dis_lr': 1e-3,\n",
    "    'mcts_sample': 10,\n",
    "    'gen_samples': 10000,\n",
    "\n",
    "    'rnn_layers': 3,\n",
    "    'rnn_bidirectional': False,\n",
    "\n",
    "    'gen_pretrain_epoch': 10,\n",
    "    'dis_pretrain_epoch': 1,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word2id:  10004\n",
      "Total id2word:  10004\n",
      "Num of positive training:  398450\n",
      "Num of positive validation:  0\n",
      "WARNING:tensorflow:From /home/wangruowen/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/wangruowen/.pyenv/versions/3.6.3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/wangruowen/.pyenv/versions/3.6.3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config, \"./data/just_tweet_without_I_will_be_interviewed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator pre-training\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "Embedding (Embedding)        (None, 15, 100)           1000400   \n",
      "_________________________________________________________________\n",
      "rnn_1 (CuDNNLSTM)            (None, 15, 128)           117760    \n",
      "_________________________________________________________________\n",
      "rnn_2 (CuDNNLSTM)            (None, 15, 128)           132096    \n",
      "_________________________________________________________________\n",
      "rnn_3 (CuDNNLSTM)            (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "DenseSoftmax (Dense)         (None, 10004)             1290516   \n",
      "=================================================================\n",
      "Total params: 2,672,868\n",
      "Trainable params: 2,672,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "3112/3112 [==============================] - 29s 9ms/step - loss: 6.2285\n",
      "Epoch 2/5\n",
      "3112/3112 [==============================] - 27s 9ms/step - loss: 5.5714\n",
      "Epoch 3/5\n",
      "3112/3112 [==============================] - 27s 9ms/step - loss: 5.1949\n",
      "Epoch 4/5\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.9366\n",
      "Epoch 5/5\n",
      "3112/3112 [==============================] - 28s 9ms/step - loss: 4.7455\n"
     ]
    }
   ],
   "source": [
    "trainer.pre_train_generator(g_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Generating 10000 sentences\n",
      "Num of all training:  560139\n",
      "Num of all validation:  0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "Embedding (Embedding)        (None, 15, 100)           1000400   \n",
      "_________________________________________________________________\n",
      "rnn_1 (CuDNNLSTM)            (None, 15, 128)           117760    \n",
      "_________________________________________________________________\n",
      "rnn_2 (CuDNNLSTM)            (None, 15, 128)           132096    \n",
      "_________________________________________________________________\n",
      "rnn_3 (CuDNNLSTM)            (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "FC (Dense)                   (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,382,481\n",
      "Trainable params: 1,382,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Discriminator pre-training\n",
      "Epoch 1/1\n",
      "4376/4376 [==============================] - 25s 6ms/step - loss: 0.2198\n"
     ]
    }
   ],
   "source": [
    "trainer.pre_train_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Q: self.t =  0\n",
      "Y_base.shape:  (128, 1)\n",
      "Call Q: self.t =  1\n",
      "Y_base.shape:  (128, 2)\n",
      "Call Q: self.t =  2\n",
      "Y_base.shape:  (128, 3)\n",
      "Call Q: self.t =  3\n",
      "Y_base.shape:  (128, 4)\n",
      "Call Q: self.t =  4\n",
      "Y_base.shape:  (128, 5)\n",
      "Call Q: self.t =  5\n",
      "Y_base.shape:  (128, 6)\n",
      "Call Q: self.t =  6\n",
      "Y_base.shape:  (128, 7)\n",
      "Call Q: self.t =  7\n",
      "Y_base.shape:  (128, 8)\n",
      "Call Q: self.t =  8\n",
      "Y_base.shape:  (128, 9)\n",
      "Call Q: self.t =  9\n",
      "Y_base.shape:  (128, 10)\n",
      "Call Q: self.t =  10\n",
      "Y_base.shape:  (128, 11)\n",
      "Call Q: self.t =  11\n",
      "Y_base.shape:  (128, 12)\n",
      "Call Q: self.t =  12\n",
      "Y_base.shape:  (128, 13)\n",
      "Call Q: self.t =  13\n",
      "Y_base.shape:  (128, 14)\n",
      "Call Q: self.t =  14\n",
      "Y_base.shape:  (128, 15)\n",
      "Reward: 0.059, Episode end\n",
      "[1, 489, 34, 96, 9708, 185, 3208, 1025, 4, 24, 1158, 11, 759, 8048, 2463, 2]\n",
      "<BOS> ll have much cleanup better per losers . s @agschneiderman in replace financially train <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Start Generating 10000 sentences\n",
      "Num of all training:  566600\n",
      "Num of all validation:  0\n",
      "Epoch 1/1\n",
      "4426/4426 [==============================] - 27s 6ms/step - loss: 0.0987\n"
     ]
    }
   ],
   "source": [
    "trainer.train(steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
